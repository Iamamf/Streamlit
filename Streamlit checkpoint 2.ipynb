{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974e1fd5-993d-4365-8115-b73103ef5a3d",
   "metadata": {},
   "source": [
    "##### In this checkpoint, we are going to work on the 'Financial Inclusion in Africa' dataset that was provided as part of the Financial Inclusion in Africa hosted by the Zindi platform.\n",
    "\n",
    "#### Dataset description: \n",
    "The dataset contains demographic information and what financial services are used by approximately 33,600 individuals across East Africa. The ML model role is to predict which individuals are most likely to have or use a bank account.\n",
    "\n",
    "The term financial inclusion means:  individuals and businesses have access to useful and affordable financial products and services that meet their \n",
    "- needs – transactions, payments, savings, credit and insurance – delivered in a responsible and sustainable way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc1d79-fad5-45b6-8608-43916ddafa0d",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "- Install the necessary packages\n",
    "- Import you data and perform basic data exploration phase\n",
    "- Display general information about the dataset\n",
    "- Create a pandas profiling reports to gain insights into the dataset\n",
    "- Handle Missing and corrupted values\n",
    "- Remove duplicates, if they exist\n",
    "- Handle outliers, if they exist\n",
    "- Encode categorical features\n",
    "- Based on the previous data exploration train and test a machine learning classifier\n",
    "- Create a streamlit application (locally) and add input fields for your features and a validation button at the end of the form\n",
    "- Import your ML model into the streamlit application and start making predictions given the provided features values\n",
    "- Deploy your application on Streamlit share:\n",
    "- Create a github and a streamlit share accounts\n",
    "- Create a new git repo\n",
    "- Upload your local code to the newly created git repo\n",
    "- log in to your streamlit account an deploy your application from the git repo\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6abd4-1061-4c15-b49f-5aebfa518bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa210857-5b90-46a2-a5ce-86daac6424a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import standard visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split #split\n",
    "from sklearn.metrics import accuracy_score #metrics\n",
    "\n",
    "#tools for hyperparameters search\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import the label Encoder library \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165c83b-caaf-475f-b022-4b03e4bf2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/HARDEY/Documents/GOMYCODE/Machine Learning/Streamlit/Streamlit Checkpoint 2/Financial_inclusion_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66231a92-7ae9-4931-9d5e-f3d1770241f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country\"] = label_encoder.fit_transform(df[\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc5628-a8ae-4020-99cc-53da3036b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4b2a5-de09-407c-872c-03cd3d0779ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a03a6-6614-4914-a697-ae71bc75ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94fb88c-4e66-4749-aac8-f702c9d52742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include =\"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94e7d8-d3f9-4ec0-a6d6-a14a9edf9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"uniqueid\", axis=1)\n",
    "df = df.drop(\"year\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12e7cf-51f0-4ea9-b529-65d8e2ae0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Optionally, if you want to reset the index after dropping duplicates:\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0d7ea-b11b-46e2-949f-9e54215fb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6487d9e-c961-472f-9e77-0cd0187f4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bank_account\"] = label_encoder.fit_transform(df[\"bank_account\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7282100-a344-4f56-8445-ecf323a2a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8334caf-3e87-4c60-b9e4-888a572801ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d53d53-6d2a-45fb-a47d-4ce8ec8bb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include='number').columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdfafa-c55d-4c1d-8376-24d8781e9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a261551-6cd7-4a34-8301-e058d0bd6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"financial_institution_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd4894-ccd2-4c02-9247-a01dfbd9bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.drop(\"bank_account\", axis=1), df[\"bank_account\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0283b76-4cf6-439f-b48f-1566e5dc9000",
   "metadata": {},
   "source": [
    "## SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391b199-f1fd-44c5-90ab-7f97a3b6144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVC model\n",
    "svc_reg = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the model to the training data\n",
    "svc_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svc = svc_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_svc = classification_report(y_test, y_pred_svc)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Support Vector Classification:\")\n",
    "print(f\"Accuracy: {accuracy_svc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_svc)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee754e-fbe1-4316-9477-eeae3f1463da",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a9417-0d66-4bcf-8226-f873259a30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gb = gb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_gb = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Gradient Boosting Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_gb:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_gb)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0482043-7e5e-464c-b164-84eb4120bb4c",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474b6b6-07a8-458e-b34f-cc4f56881bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = knn_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"K-Nearest Neighbors Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_knn)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b5af2-578c-4eb5-999b-91372a6f4fce",
   "metadata": {},
   "source": [
    "## DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfad2fa-3ce6-42b2-900b-8c2a057a2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_tree = tree_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Decision Tree Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_tree:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_tree)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ddd62-98ab-43fb-9bc8-9b98c53db37d",
   "metadata": {},
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e6cdc-1cc3-4583-82ad-fd4295ce3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "forest_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_forest = forest_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_forest = classification_report(y_test, y_pred_forest)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Random Forest Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_forest:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_forest)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bed24-3d56-4e40-ba82-514287086b71",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af4ef9-a42c-4e97-85d2-12d3ed295ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Predict on the training data (for train evaluation)\n",
    "y_train_pred_log = log_reg.predict(X_train_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_log = confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_log = classification_report(y_test, y_pred_log)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_log:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_log)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed3b5d-4027-46d4-986f-300d2e30459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train,y_train.squeeze().values)\n",
    "\n",
    "#calculate and print scores for the model for the features\n",
    "y_train_preds = xgb.predict(X_train_scaled)\n",
    "y_test_preds = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_xgb = accuracy_score(y_test, y_test_preds)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_test_preds)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report_xgb = classification_report(y_test, y_test_preds)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"xgboost:\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_xgb)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4bae57-5953-4403-be0c-d2fca7a4066a",
   "metadata": {},
   "source": [
    "## Randomized Search for Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c78158-8325-4250-8fcb-a2d5f809ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100],       # Number of boosting stages\n",
    "    'learning_rate': [0.1, 0.2],     # Shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, ],                # Maximum depth of individual trees\n",
    "    'min_samples_split': [5, 10],       # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [4],         # Minimum number of samples required to be at a leaf node\n",
    "    'subsample': [ 1.0]                # Fraction of samples used for fitting individual base learners\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gb_clf, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "best_gb_clf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_best_gb = best_gb_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance on test data\n",
    "accuracy_best_gb = accuracy_score(y_test, y_pred_best_gb)\n",
    "print(f\"Test Accuracy after tuning: {accuracy_best_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee70f6-4927-441c-b465-08349296e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c9fcd-99f5-4ac9-bca2-92c22c492bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"financial_institution_cleaned.csv\")\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa070a5-4d5f-41a0-a188-caf862001565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "df = pd.read_csv(\"Downloads/financial_institution_cleaned.csv\")\n",
    "\n",
    "df[\"bank_account\"] = df.target\n",
    "df['bank_account'] = pd.Categorical.from_codes(df.target, df.target_names)\n",
    "\n",
    "st.title(\"financial institution classification\")\n",
    "st.write(\"\"\"\n",
    "This app uses **Gradient Boosting Classifier** to predict which individuals are most likely to have or use a bank account.\n",
    "\"\"\")\n",
    "\n",
    "st.write(\"### Financial dataset\", df)\n",
    "\n",
    "st.sidebar.header('User Input Parameters')\n",
    "\n",
    "def user_input_features():\n",
    "\n",
    "\n",
    "    # Slider for Sepal Length\n",
    "    # Set the label, minimum value, maximum value, and default value (mean) for the slider\n",
    "    country = st.sidebar.selectbox(\n",
    "        'Country of Residence',  # Label displayed for the slider\n",
    "        float(df['country'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    location_type = st.sidebar.selectbox(\n",
    "        'Location Type',  # Label displayed for the slider\n",
    "        float(df['location_type'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    cellphone_access = st.sidebar.selectbox(\n",
    "        'Cellphone Access',  # Label displayed for the slider\n",
    "        float(df['cellphone_access'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    household_size = st.sidebar.slider(\n",
    "        'Household Size',  # Label displayed for the slider\n",
    "        float(df['household_size'].min()),  # Minimum value from the dataset\n",
    "        float(df['household_size'].max()),  # Maximum value from the dataset\n",
    "        float(df['household_size'].mean())  # Default value set to the mean of sepal lengths\n",
    "    )\n",
    "\n",
    "    age_of_respondent = st.sidebar.slider(\n",
    "        'Respondent Age',  # Label displayed for the slider\n",
    "        float(df['age_of_respondent'].min()),  # Minimum value from the dataset\n",
    "        float(df['age_of_respondent'].max()),  # Maximum value from the dataset\n",
    "        float(df['age_of_respondent'].mean())  # Default value set to the mean of sepal lengths\n",
    "    )\n",
    "\n",
    "    gender_of_respondent = st.sidebar.selectbox(\n",
    "        'Gender of Respondent',  # Label displayed for the slider\n",
    "        float(df['gender_of_respondent'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    relationship_with_head = st.sidebar.selectbox(\n",
    "        'Relationship with Head of Household',  # Label displayed for the slider\n",
    "        float(df['relationship_with_head'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    marital_status = st.sidebar.selectbox(\n",
    "        'Marital Status',  # Label displayed for the slider\n",
    "        float(df['marital_status'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    education_level = st.sidebar.selectbox(\n",
    "        'Education level',  # Label displayed for the slider\n",
    "        float(df['education_level'])\n",
    "        \n",
    "    )\n",
    "\n",
    "    job_type = st.sidebar.selectbox(\n",
    "        'Job Type',  # Label displayed for the slider\n",
    "        float(df['job_type'])\n",
    "    )\n",
    "\n",
    "    data = {'Country of Residence': country,\n",
    "            'Location Type': location_type,\n",
    "            'Cellphone Access': cellphone_access,\n",
    "            'Household Size': household_size,\n",
    "            'Gender of Respondent': age_of_respondent,\n",
    "            'Relationship with Head of Household': relationship_with_head,\n",
    "            'Marital Status': marital_status,\n",
    "            'Education level': education_level,\n",
    "            'Job Type': job_type}\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "\n",
    "input_df = user_input_features()\n",
    "\n",
    "X = pd.DataFrame(df.data, columns=df.feature_names)  # Convert to DataFrame\n",
    "Y = df.target\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Make predictions\n",
    "prediction = gb_clf.predict(input_df)\n",
    "prediction_proba = gb_clf.predict_proba(input_df)\n",
    "\n",
    "st.subheader('Prediction')\n",
    "st.write(df.target_names[prediction])\n",
    "\n",
    "st.subheader('Prediction Probability')\n",
    "st.write(prediction_proba)\n",
    "\n",
    "\n",
    "#### Step 5: Visualizing Results\n",
    "\n",
    "# You can use Streamlit's `st.line_chart()` or `st.bar_chart()` to show charts or integrate Matplotlib/Plotly for custom visualizations.\n",
    "\n",
    "\n",
    "# Visualization Example: Show the feature importance\n",
    "st.subheader('Feature Importance')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = gb_clf.feature_importances_\n",
    "features = df.feature_names\n",
    "plt.barh(features, importance)\n",
    "st.pyplot(plt)\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e51e6620-7a20-484c-b74f-afc4e1f6edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stream_user_financial_classifier.py\", \"w\") as file:\n",
    "    file.write('''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Downloads/financial_institution_cleaned.csv\")\n",
    "\n",
    "# Assuming 'target' column contains the labels for whether a person has a bank account or not\n",
    "X = df.drop(columns=['bank_account'])  # Features\n",
    "Y = df['bank_account']  # Target labels\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the classifier\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0\n",
    ")\n",
    "gb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Streamlit app title\n",
    "st.title(\"Financial Institution Classification\")\n",
    "\n",
    "# App description\n",
    "st.write(\"\"\"\n",
    "This app uses **Gradient Boosting Classifier** to predict which individuals are most likely to have or use a bank account.\n",
    "\"\"\")\n",
    "\n",
    "# Display the dataset\n",
    "st.write(\"### Financial Dataset Sample\", df.head())\n",
    "\n",
    "# Sidebar for user inputs\n",
    "st.sidebar.header('User Input Parameters')\n",
    "\n",
    "def user_input_features():\n",
    "    country = st.sidebar.selectbox(\"country\", [\"country_Kenya\", \"country_Rwanda\", \"country_Tanzania\", \"country_Uganda\"])\n",
    "    location_type = st.sidebar.selectbox(\"location_type\", [\"location_type_Rural\", \"location_type_Urban\"])\n",
    "    cellphone_access = st.sidebar.selectbox('cellphone_access', ['cellphone_access_No', 'cellphone_access_Yes'])\n",
    "    household_size = st.sidebar.slider('Household Size', int(df['household_size'].min()), int(df['household_size'].max()), int(df['household_size'].mean()))\n",
    "    age_of_respondent = st.sidebar.slider('Respondent Age', int(df['age_of_respondent'].min()), int(df['age_of_respondent'].max()), int(df['age_of_respondent'].mean()))\n",
    "    gender_of_respondent = st.sidebar.selectbox(\"gender_of_respondent\", ['gender_of_respondent_Female', 'gender_of_respondent_Male'])\n",
    "    relationship_with_head = st.sidebar.selectbox('relationship_with_head', ['relationship_with_head_Child', 'relationship_with_head_Head_of_Household', 'relationship_with_head_Other_non_relatives', 'relationship_with_head_Other_relative', 'relationship_with_head_Parent', 'relationship_with_head_Spouse'])\n",
    "    marital_status = st.sidebar.selectbox('marital_status', ['marital_status_Divorced_Seperated', 'marital_status_Dont_know', 'marital_status_Married_Living_together', 'marital_status_Single_Never_Married', 'marital_status_Widowed'])\n",
    "    education_level = st.sidebar.selectbox('education_level', ['education_level_No_formal_education', 'education_level_Other_Dont_know_RTA', 'education_level_Primary_education', 'education_level_Secondary_education', 'education_level_Tertiary_education', 'education_level_Vocational_Specialised_training'])\n",
    "    job_type = st.sidebar.selectbox('job_type', ['job_type_Dont_Know_Refuse_to_answer', 'job_type_Farming_and_Fishing', 'job_type_Formally_employed_Government', 'job_type_Formally_employed_Private', 'job_type_Government_Dependent', 'job_type_Informally_employed', 'job_type_No_Income', 'job_type_Other_Income', 'job_type_Remittance_Dependent', 'job_type_Self_employed'])\n",
    "\n",
    "    data = {\n",
    "        'country': country,\n",
    "        'location_type': location_type,\n",
    "        'cellphone_access': cellphone_access,\n",
    "        'household_size': household_size,\n",
    "        'age_of_respondent': age_of_respondent,\n",
    "        'gender_of_respondent': gender_of_respondent,\n",
    "        'relationship_with_head': relationship_with_head,\n",
    "        'marital_status': marital_status,\n",
    "        'education_level': education_level,\n",
    "        'job_type': job_type\n",
    "    }\n",
    "\n",
    "    # Convert the input data into a DataFrame\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    \n",
    "    # Align the features with the training data (adding missing columns if necessary)\n",
    "    features = features.reindex(columns=X_train.columns, fill_value=0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "input_df = user_input_features()\n",
    "\n",
    "# Make predictions based on user input\n",
    "prediction = gb_clf.predict(input_df)\n",
    "prediction_proba = gb_clf.predict_proba(input_df)\n",
    "\n",
    "# Display the prediction results\n",
    "st.subheader('Prediction')\n",
    "st.write(f\"Predicted Bank Account Status: {'Has Bank Account' if prediction[0] == 1 else 'No Bank Account'}\")\n",
    "\n",
    "st.subheader('Prediction Probability')\n",
    "st.write(prediction_proba)\n",
    "\n",
    "# Feature importance visualization\n",
    "st.subheader('Feature Importance')\n",
    "importance = gb_clf.feature_importances_\n",
    "features = X.columns\n",
    "plt.barh(features, importance)\n",
    "st.pyplot(plt)\n",
    "\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
